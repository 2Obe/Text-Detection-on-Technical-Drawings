{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11768990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageOps, ImageEnhance\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = '' \n",
    "TF_RECORD_SCRIPT_NAME = ''\n",
    "LABEL_MAP_NAME = ''\n",
    "\n",
    "\n",
    "paths = {\n",
    "   \n",
    "    'CHECKPOINT_PATH': os.path.join('PATH',CUSTOM_MODEL_NAME),  \n",
    "    'ANNOTATION_PATH': os.path.join('PATH','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('PATH'),\n",
    "    'SCRIPTS_PATH': os.path.join('PATH','tensorflow','scripts'),\n",
    " }\n",
    "\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('PATH', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91efde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'CHECKPOINT')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d72da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'IMAGE_FOR_DETECTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c74bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,            \n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=50,\n",
    "            min_score_thresh=0.25,\n",
    "            line_thickness=1,\n",
    "            skip_labels=True,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "\n",
    "picture= cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('detection.jpg', picture)\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.imshow(picture)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_threshold = 0.25\n",
    "image = cv2.imread(IMAGE_PATH)\n",
    "\n",
    " \n",
    "scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
    "boxes = detections['detection_boxes'][:len(scores)]\n",
    "classes = detections['detection_classes'][:len(scores)]\n",
    "\n",
    "width = image.shape[1]\n",
    "height = image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste=[]\n",
    "m=0\n",
    "\n",
    "\n",
    "while m<len(classes):\n",
    "    if classes[m]==0 or classes[m]==1:\n",
    "        liste.append(m)\n",
    "    \n",
    "    \n",
    "    m+=1\n",
    " \n",
    "print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53980c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_filtered=[]\n",
    "\n",
    "for i in liste:\n",
    "    scores_filtered.append(scores[i])\n",
    "\n",
    "    \n",
    "print(scores_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_filtered=[]\n",
    "\n",
    "for i in liste:\n",
    "    boxes_filtered.append(boxes[i])\n",
    "    \n",
    "print(boxes_filtered)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca481bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "outputs=[]\n",
    "text=''\n",
    "\n",
    "while i<len(scores_filtered):\n",
    "    roi = boxes_filtered[i]*[height, width, height, width]        \n",
    "    region = image[int(roi[0])-5:int(roi[2])+5,int(roi[1])-5:int(roi[3])+5]\n",
    "    bild = region.shape\n",
    "    \n",
    "    if region.shape[0]>region.shape[1]+5:\n",
    "        region = np.rot90(region,-1)\n",
    "        \n",
    "    img = cv2.cvtColor(region, cv2.COLOR_BGR2RGB)        \n",
    "    cv2.imwrite('detection_ocr%s.jpg'% i, img)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
